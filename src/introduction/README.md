# Introduction

TODO:

- [ ] Neurons
  - [ ] Activations
    - [ ] Sigmoid
    - [ ] ReLU
    - [ ] Leaky ReLU
- [ ] Layers
  - [ ] Fully Connected
  - [ ] Convolutional
  - [ ] Recurrent
  - [ ] Pooling
  - [ ] Normalization