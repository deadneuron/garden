# Introduction

![Network](/images/intro-nn.svg)

TODO:

- [ ] Neurons
  - [ ] Activations
    - [ ] Sigmoid
    - [ ] ReLU
    - [ ] Leaky ReLU
- [ ] Layers
  - [ ] Fully Connected
  - [ ] Convolutional
  - [ ] Recurrent
  - [ ] Pooling
  - [ ] Normalization
- [ ] Initialization
  - [ ] Kaiming
  - [ ] Xavier
  - [ ] Orthogonal
- [ ] Optimization
  - [ ] Gradient Descent
  - [ ] Neuro-Evolution
